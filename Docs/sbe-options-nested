import sqlite3
import xml.etree.ElementTree as ET
from multiprocessing import Pool, cpu_count
from tqdm import tqdm

# Function to determine Sub ID
def extract_sub_id(element):
    sub_id_element = element.find('.//fixml:Sub', ns)
    return sub_id_element.get('ID') if sub_id_element is not None else None

# Function to extract attribute values from the XML elements
def extract_attributes(element, attribute_names):
    return [element.get(attr) for attr in attribute_names]

# Function to process a batch of TrdCaptRpt elements
def process_batch(trade_elements):
    for trd_capt_rpt in trade_elements:
        quantity, side, rpt_id = extract_attributes(trd_capt_rpt, ['LastQty', 'Side', 'RptID'])

        for rpt_side in trd_capt_rpt.findall('fixml:RptSide', ns):
            for pty in rpt_side.findall('fixml:Pty', ns):
                pty_id, pty_r, sub_id = extract_attributes(pty, ['ID', 'R']), extract_sub_id(pty)

                # Insert the extracted data into the SQLite table
                cursor.execute('INSERT INTO trades VALUES (?, ?, ?, ?, ?, ?)',
                               (quantity, side, pty_id, pty_r, sub_id, rpt_id))

# Connect to the SQLite database
conn = sqlite3.connect('trades.db')
cursor = conn.cursor()

# Create the table for storing the trade data
cursor.execute('''CREATE TABLE IF NOT EXISTS trades (
                    Quantity INTEGER,
                    Side TEXT,
                    Pty_ID TEXT,
                    Pty_R TEXT,
                    Sub_ID TEXT,
                    Rpt_ID TEXT
                 )''')

# Define the namespace
ns = {'fixml': 'http://www.fixprotocol.org/FIXML-4-4'}

# Parse the XML data and extract the required attributes
print("Parsing the XML data...")
tree_trade = ET.parse('path_to_your_large_xml.xml')
root_trade = tree_trade.getroot()
trade_elements = root_trade.findall('.//fixml:TrdCaptRpt', ns)

# Split the data into batches based on the number of CPU cores
num_cores = cpu_count()
batch_size = len(trade_elements) // num_cores
trade_batches = [trade_elements[i:i + batch_size] for i in range(0, len(trade_elements), batch_size)]

# Use parallel processing to insert data
print("Extracting data from the XML and inserting into the database...")
with Pool(processes=num_cores) as pool, tqdm(total=len(trade_elements)) as pbar:
    for _ in pool.imap_unordered(process_batch, trade_batches):
        pbar.update(batch_size)

# Commit the changes and close the connection
conn.commit()
conn.close()

print("Data has been successfully stored in the SQLite database.")
