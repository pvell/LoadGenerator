import configparser
import socket
import struct
import time
from multiprocessing import Process
from sbe_encoder_decoder import UTCTimestampNanos, NewOrderSingle, ShortTwoSidedQuote, ShortTwoSideBulkQuote, LongTwoSideBulkQuote, ShortOneSideBulkQuote, LongOneSideBulkQuote, MatchTradePreventionType, MtpGroupIDType, LongOneSideQuote, LongTwoSidedQuote, UINT32, UINT16, OrdType, PriceType, TimeInForceType, ExecInstType, TradingCapacityType, SideType, PartyID, PartiesGroup, PartyIDSource, PartyRoleType, OptionsSecurityID, ShortOneSideQuote
from random import choices, randint
import string

# Rest of the script remains the same

def session_worker(session_name):
    try:
        # Establish SBE TCP session for the current session name
        client_socket, session_id = establish_session(session_name)

        # Start time for calculating duration
        start_time = time.time()

        # Generate and send messages for the specified duration
        while time.time() - start_time < duration:
            # Generate a random message type
            message_type = generate_message_type()

            # Generate a message based on the random message type
            message = generate_message(message_type, session_name)

            # Send the generated message over the TCP connection
            send_message(client_socket, message)

            # Sleep for a short period to control the message rate
            time.sleep(1 / message_rate)

        # Close the TCP connection for the current session
        client_socket.close()

    except Exception as e:
        print(f"Failed to establish session for {session_name}: {str(e)}")

def main():
    # Read session names from connections.cfg
    session_names = connection_config.sections()

    # List to hold the worker processes
    processes = []

    # Iterate over session names and create worker processes
    for session_name in session_names:
        process = Process(target=session_worker, args=(session_name,))
        processes.append(process)

    # Start all the worker processes
    for process in processes:
        process.start()

    # Wait for all worker processes to complete
    for process in processes:
        process.join()

    # Print the number of active sessions
    print(f"Total active sessions: {len(processes)}")

# Start the main execution
if __name__ == '__main__':
    main()













import configparser
import socket
import struct
import time
from sbe_encoder_decoder import UTCTimestampNanos, NewOrderSingle, ShortTwoSidedQuote, ShortTwoSideBulkQuote, LongTwoSideBulkQuote, ShortOneSideBulkQuote, LongOneSideBulkQuote, MatchTradePreventionType, MtpGroupIDType, LongOneSideQuote, LongTwoSidedQuote
from sbe_encoder_decoder import UINT32, UINT16, OrdType, PriceType, TimeInForceType, ExecInstType, TradingCapacityType, SideType, PartyID, PartiesGroup, PartyIDSource, PartyRoleType, ShortPriceType, OptionsSecurityID, ShortOneSideQuote
from random import choices, randint
import string
import threading

# ... (other imports and configurations)

# Function to establish SBE TCP session
def establish_session(session_name):
    # ... (session establishment logic)
    return client_socket, session_id

# Function to handle workload for each session
def session_workload(session_name):
    try:
        client_socket, session_id = establish_session(session_name)
        
        start_time = time.time()
        while time.time() - start_time < duration:
            message_type = generate_message_type()
            message = generate_message(message_type, session_name)
            send_message(client_socket, message)
            time.sleep(1 / message_rate)
        
        client_socket.close()

    except Exception as e:
        print(f"Failed to establish session for {session_name}: {str(e)}")

def main():
    # Read session names from connections.cfg
    session_names = connection_config.sections()

    # List to hold thread objects
    threads = []

    # Iterate over session names and create threads
    for session_name in session_names:
        thread = threading.Thread(target=session_workload, args=(session_name,))
        threads.append(thread)

    # Start all threads
    for thread in threads:
        thread.start()

    # Wait for all threads to finish
    for thread in threads:
        thread.join()

    print(f"Total active sessions: {len(session_names)}")

# Start the main execution
if __name__ == '__main__':
    main()








class MyApplication(fix.Application):
    def __init__(self, message_weights, message_rate):
        super().__init__()
        self.message_weights = message_weights
        self.message_rate = message_rate
        self.sessions = {}
        self.log_directory = "log"
        self.captured_clordids = []
        self.efid_map = {}
        self.captured_clordid_side_mapping = {}

        # Load EFID mapping from config
        efid_mapping = dict(config.items("EFID"))
        for comp_id, efid in efid_mapping.items():
            efid, trading_capacity = efid.split(",")
            self.efid_map[comp_id] = {"efid": efid, "trading_capacity": int(trading_capacity)}




def generate_message(self, message_type, session_id):
    sender_comp_id = session_id.getSenderCompID().getString()
    efid_info = self.efid_map.get(sender_comp_id)
    
    if efid_info is None:
        print(f"EFID mapping not found for SenderCompID: {sender_comp_id}")
        return None

    efid = efid_info["efid"]
    trading_capacity = efid_info["trading_capacity"]

    # Rest of the function...

















# Define the MESSAGE_TYPES dictionary
MESSAGE_TYPES = {
    "NewOrderSingle": 1,
    "ShortTwoSidedBulkQuote": 2,
    "LongTwoSidedBulkQuote": 3,
    "ShortOneSidedBulkQuote": 4,
    "LongOneSidedBulkQuote": 5,
    "ExecutionReport_New": 11,
    "ExecutionReport_BulkQuote_PendingNew": 12,
    "ExecutionReport_BulkQuote_ComponentNew": 13,
    "ExecutionReport_Rejected": 14,
    "ExecutionReport_Trade": 15,
    "ExecutionReport_PendingCancel": 16,
    "ExecutionReport_Canceled": 17,
    "ExecutionReport_PendingReplace": 18,
    "ExecutionReport_Replaced": 19,
    "ExecutionReport_TradeCorrection": 20,
    "ExecutionReport_TradeBreak": 21,
    "ExecutionReport_Restatement": 22,
    "PendingMassCancel": 23,
    "MassCancelReject": 24,
    "MassCancelDone": 25,
    "OrderCancelReject": 26,
    "AllocationInstructionAck": 27,
    "AllocationReport": 28,
    "UserNotification": 29,
    "MassCancelClearLockoutReject": 30,
    "MassCancelClearLockoutDone": 31
}

# After extracting the Template ID from SBE header
message_type_name = None
for message_name, template_id_value in MESSAGE_TYPES.items():
    if template_id == template_id_value:
        message_type_name = message_name
        break

if message_type_name:
    print("Message Type Name:", message_type_name)
else:
    print("Unknown Message Type")


# After sending the message and before processing the response
send_message(client_socket, message)

# Receive 10 bytes of the response
response_data = client_socket.recv(10)

# Extract TCP header fields
response_type, response_length = struct.unpack('!B H', response_data[:3])

# Extract SBE header fields
sbe_header_data = response_data[3:]
block_length, template_id, schema_id, version, num_groups = struct.unpack('!H B B H B', sbe_header_data)

# Print extracted header fields
print("Template ID:", template_id)
print("Message Type:", message_name












def decode_ER_New(data):
    offsets = {
        'OrderID': 7,
        'ClOrdID': 15,
        'ListSeqNo': 35,
        'ExecID': 36,
        'OrdStatus': 44,
        'OptionsSecurityID': 45,
        'Side': 53,
        'OrderQty': 54,
        'OrdType': 58,
        'Price': 59,
        'TimeInForce': 67,
        'OpenOrClose': 68,
        'ExecInst': 69,
        'TradingCapacity': 71,
        'RepriceFrequency': 72,
        'RepriceBehavior': 73,
        'LeavesQty': 74,
        'CumQty': 78,
        'SendingTime': 82,
        'TransactTime': 90,
        'MtpGroupID': 98,
        'MatchTradePrevention': 100,
        'CancelGroupID': 101,
        'RiskGroupID': 103
    }

    decoded_message = {}
    for field, offset in offsets.items():
        field_size = struct.unpack('!H', data[offset - 2:offset])[0]
        field_data = data[offset:offset + field_size]
        if field_size == 1:
            decoded_message[field] = struct.unpack('!B', field_data)[0]
        else:
            decoded_message[field] = field_data.decode('utf-8').strip('\x00')
    
    return decoded_message

def decode_BulkQuote_pending_new(data):
    offsets = {
        'ClOrdID': 7,
        'Symbol': 27,
        'TimeInForce': 33,
        'ExecInst': 34,
        'TradingCapacity': 36,
        'SendingTime': 37,
        'TransactTime': 45,
        'MtpGroupID': 53,
        'MatchTradePrevention': 55,
        'CancelGroupID': 56,
        'RiskGroupID': 58,
        'NumberOfOrders': 60
    }

    decoded_message = {}
    for field, offset in offsets.items():
        field_size = struct.unpack('!H', data[offset - 2:offset])[0]
        field_data = data[offset:offset + field_size]
        if field_size == 1:
            decoded_message[field] = struct.unpack('!B', field_data)[0]
        else:
            decoded_message[field] = field_data.decode('utf-8').strip('\x00')
    
    return decoded_message

# Add similar decode functions for other message types

# Call the decoders based on the template ID
template_id = struct.unpack('!B', response_data[2:3])[0]

if template_id == 11:
    decoded_message = decode_ER_New(response_data[3:])
elif template_id == 12:
    decoded_message = decode_BulkQuote_pending_new(response_data[3:])
# Add similar conditional statements for other template IDs

print(decoded_message)






#!/bin/bash
date="$1"
db_name="$date.db"

# Step 1: Split the big XML file using split.py
python3 split_v4.py orsa_trades_2023-"$date".xml "$date"

# Step 2: Process each split file using xml_to_db.py
for split_file in "$date"_*; do
    python3 xml_2_db_v4.py "$split_file" "$db_name" > log.txt &

    # Capture the PID of the last background process
    pid=$!

    # Wait for the background process to complete
    wait "$pid"

    echo "Processing of $split_file completed."
done

# Step 3: Group the data in the database using groupedexcel.py
python3 groupedexcel_v4.py "$db_name"

grouped_pid=$!
# Wait for groupedexcel.py to complete
wait "$grouped_pid"

echo "Grouping of data completed."

# Step 4: Perform further processing using furtherstreaming.py
python3 streamfurther_v4.py "$db_name"


